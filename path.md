# L2DClaw â€” Claude Code å¼€å‘ Prompt v2

## é¡¹ç›®èƒŒæ™¯ä¸ç›®æ ‡

ä½ æ­£åœ¨å¸®æˆ‘æ„å»ºä¸€ä¸ªåä¸º **L2DClaw** çš„ Live2D æ¡Œå® é¡¹ç›®ã€‚

- **GitHub ä»“åº“**ï¼šhttps://github.com/YiniRuohong/L2DClaw
- **æ ¸å¿ƒç›®æ ‡**ï¼šæœ¬åœ°è¿è¡Œçš„ Live2D æ¡Œå® ï¼Œæ„ŸçŸ¥æ¡Œé¢çŠ¶æ€å’Œè¯­éŸ³è¾“å…¥ï¼Œé€šè¿‡äº‘ç«¯ OpenClawï¼ˆOpenAI å…¼å®¹ APIï¼‰å†³ç­–åé©±åŠ¨ Live2D è¡¨æƒ…åŠ¨ä½œ + æœ¬åœ° Qwen3 TTS è¯­éŸ³è¾“å‡ºã€‚
- **åŸåˆ™**ï¼šå°½é‡å°‘é€ è½®å­ï¼Œä¼˜å…ˆå¤ç”¨æˆç†Ÿå¼€æºé¡¹ç›®ã€‚
- **å¹³å°æ”¯æŒ**ï¼šWindows 10/11 + macOS 12+ï¼Œä»£ç ä¸­æ‰€æœ‰å¹³å°ç›¸å…³é€»è¾‘å¿…é¡»åŒå¹³å°å®ç°ã€‚

---

## æ¶æ„æ€»è§ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  é¦–æ¬¡å¯åŠ¨å‘å¯¼                          â”‚
â”‚  ç”¨æˆ·è®¸å¯åè®® â†’ é€‰æ‹©åŠŸèƒ½ â†’ ä¸‹è½½æœ¬åœ° TTS æ¨¡å‹           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ å®Œæˆåè¿›å…¥ä¸»ç¨‹åº
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  æœ¬åœ° Adapter å±‚                      â”‚
â”‚                                                      â”‚
â”‚  AdapterBase (æŠ½è±¡åŸºç±»)                               â”‚
â”‚  â”œâ”€â”€ ScreenAdapter      # çª—å£ä¿¡æ¯ + ç”»é¢å†…å®¹è¯†åˆ«     â”‚
â”‚  â”œâ”€â”€ VoiceAdapter       # VAD + Whisper ASR          â”‚
â”‚  â”œâ”€â”€ KeyboardAdapter    # æ‰“å­—æ´»è·ƒåº¦æ„ŸçŸ¥ (å¯é€‰)        â”‚
â”‚  â””â”€â”€ [HardwareAdapter]  # é¢„ç•™æ¥å£ï¼Œæœªæ¥æ¥å…¥ç¡¬ä»¶è®¾å¤‡  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ ç»“æ„åŒ– context
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           OpenClaw äº‘ç«¯å¤§è„‘ï¼ˆOpenAI å…¼å®¹ï¼‰             â”‚
â”‚  è¾“å…¥: {context, user_text}                           â”‚
â”‚  è¾“å‡º: {text, emotion, motion}                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
     â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Live2D é©±åŠ¨  â”‚  â”‚  æœ¬åœ° Qwen3 TTS å¼•æ“  â”‚
â”‚ (Open-LLM-   â”‚  â”‚  (æ¨¡å‹æœ¬åœ°è¿è¡Œï¼Œ      â”‚
â”‚  VTuber å‰ç«¯)â”‚  â”‚   é¦–æ¬¡å¯åŠ¨æ—¶ä¸‹è½½)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ç›®å½•ç»“æ„

```
L2DClaw/
â”œâ”€â”€ README.md
â”œâ”€â”€ conf.yaml                            # ä¸»é…ç½®æ–‡ä»¶
â”œâ”€â”€ .env.example                         # ç¯å¢ƒå˜é‡æ¨¡æ¿
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ main.py                              # å¯åŠ¨å…¥å£ï¼ˆæ£€æµ‹é¦–æ¬¡è¿è¡Œ â†’ å‘å¯¼ or ä¸»ç¨‹åºï¼‰
â”‚
â”œâ”€â”€ setup/                               # é¦–æ¬¡å¯åŠ¨å‘å¯¼
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ wizard.py                        # å‘å¯¼ä¸»é€»è¾‘ï¼ˆCLI äº¤äº’å¼ï¼‰
â”‚   â”œâ”€â”€ license.txt                      # ç”¨æˆ·è®¸å¯åè®®æ–‡æœ¬
â”‚   â””â”€â”€ model_downloader.py              # ä¸‹è½½æœ¬åœ° TTS æ¨¡å‹
â”‚
â”œâ”€â”€ adapter/                             # æ„ŸçŸ¥é‡‡é›†å±‚ï¼ˆå¯æ‰©å±•æ¥å£è®¾è®¡ï¼‰
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py                          # AdapterBase æŠ½è±¡åŸºç±»
â”‚   â”œâ”€â”€ adapter_manager.py               # ç»Ÿä¸€ç®¡ç†æ‰€æœ‰ Adapter
â”‚   â”œâ”€â”€ screen/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ screen_adapter.py            # ç»§æ‰¿ AdapterBase
â”‚   â”‚   â”œâ”€â”€ window_watcher.py            # çª—å£æ ‡é¢˜/è¿›ç¨‹ï¼ˆWin + macOSï¼‰
â”‚   â”‚   â””â”€â”€ content_recognizer.py        # ç”»é¢å†…å®¹è¯†åˆ«ï¼ˆæˆªå›¾ + VLMï¼‰
â”‚   â”œâ”€â”€ voice/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ voice_adapter.py             # ç»§æ‰¿ AdapterBase
â”‚   â”‚   â”œâ”€â”€ vad.py                       # è¯­éŸ³æ´»åŠ¨æ£€æµ‹
â”‚   â”‚   â””â”€â”€ asr.py                       # Whisper è¯­éŸ³è¯†åˆ«
â”‚   â”œâ”€â”€ keyboard/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ keyboard_adapter.py          # ç»§æ‰¿ AdapterBaseï¼Œæ„ŸçŸ¥æ‰“å­—æ´»è·ƒåº¦
â”‚   â””â”€â”€ hardware/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ hardware_adapter_base.py     # é¢„ç•™ç¡¬ä»¶è®¾å¤‡æ¥å£ï¼ˆç©ºå®ç° + æ–‡æ¡£ï¼‰
â”‚
â”œâ”€â”€ brain/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ openclaw_client.py
â”‚   â””â”€â”€ response_parser.py
â”‚
â”œâ”€â”€ live2d_driver/
â”‚   â”œâ”€â”€ frontend/                        # Fork è‡ª Open-LLM-VTuber å‰ç«¯
â”‚   â””â”€â”€ driver_server.py
â”‚
â”œâ”€â”€ tts/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py                          # TTSBase æŠ½è±¡åŸºç±»ï¼ˆé¢„ç•™æ‰©å±•ï¼‰
â”‚   â”œâ”€â”€ local_qwen3_tts.py               # æœ¬åœ° Qwen3 TTSï¼ˆé¦–é€‰ï¼‰
â”‚   â””â”€â”€ dashscope_tts.py                 # DashScope äº‘ç«¯å¤‡ç”¨ï¼ˆç½‘ç»œä¸å¥½æ—¶é™çº§ï¼‰
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ upstream_analysis.md
    â”œâ”€â”€ adapter_extension_guide.md       # å¦‚ä½•æ–°å¢è‡ªå®šä¹‰ Adapterï¼ˆç¡¬ä»¶æ¥å…¥æŒ‡å—ï¼‰
    â””â”€â”€ architecture.md
```

---

## Step 0ï¼šåˆ†æä¸Šæ¸¸é¡¹ç›®

Clone Open-LLM-VTuber åˆ°ä¸´æ—¶ç›®å½•å¹¶åˆ†æï¼š

```bash
git clone https://github.com/Open-LLM-VTuber/Open-LLM-VTuber.git _upstream_reference --depth=1
```

åˆ†æä»¥ä¸‹å†…å®¹ï¼Œå†™å…¥ `docs/upstream_analysis.md`ï¼š

1. **LLM æ¥å…¥æ–¹å¼**ï¼š`conf.yaml` ä¸­å¦‚ä½•é…ç½® OpenAI-compatible endpoint
2. **WebSocket åè®®**ï¼šå‰ç«¯ Live2D é€šè¿‡ WebSocket æ¥æ”¶ä»€ä¹ˆæ ¼å¼çš„ JSON æŒ‡ä»¤
3. **TTS æ¥å£æŠ½è±¡**ï¼šTTS æ¨¡å—çš„åŸºç±»åœ¨å“ªé‡Œï¼Œå¦‚ä½•æ–°å¢ provider
4. **å±å¹•æ„ŸçŸ¥å®ç°**ï¼šScreen Sense åŠŸèƒ½ä»£ç ä½ç½®å’Œè§¦å‘æ–¹å¼
5. **æ¡Œå® æ¨¡å¼å®ç°**ï¼šé€æ˜+ç½®é¡¶+ç©¿é€åœ¨å“ªé‡Œé…ç½®ï¼ˆElectron/Tauri é…ç½®é¡¹ï¼‰

---

## Step 1ï¼šé¦–æ¬¡å¯åŠ¨å‘å¯¼

`main.py` å¯åŠ¨æ—¶å…ˆæ£€æµ‹æ˜¯å¦é¦–æ¬¡è¿è¡Œï¼ˆé€šè¿‡ `~/.l2dclaw/initialized` æ ‡å¿—æ–‡ä»¶åˆ¤æ–­ï¼‰ã€‚
è‹¥æ˜¯é¦–æ¬¡è¿è¡Œï¼Œè¿›å…¥å‘å¯¼æµç¨‹ã€‚

### setup/wizard.py â€” CLI äº¤äº’å¼å‘å¯¼

```
======================================
  æ¬¢è¿ä½¿ç”¨ L2DClaw æ¡Œå®  ğŸ¾
======================================

ã€ç”¨æˆ·è®¸å¯åè®®ã€‘
ï¼ˆå±•ç¤º license.txt å†…å®¹ï¼Œåˆ†é¡µæ»šåŠ¨ï¼‰

ä½ æ˜¯å¦åŒæ„ä»¥ä¸Šè®¸å¯åè®®ï¼Ÿ[y/N] > y

ã€åŠŸèƒ½é…ç½®ã€‘
ä»¥ä¸‹æ˜¯å¯é€‰åŠŸèƒ½ï¼Œè¯·æ ¹æ®éœ€æ±‚å¼€å¯ï¼š

[1] å±å¹•ç”»é¢å†…å®¹è¯†åˆ«ï¼ˆæˆªå›¾åˆ†æï¼‰  é»˜è®¤: å…³é—­
    âš  æˆªå›¾å°†å‘é€ç»™ OpenClaw äº‘ç«¯ï¼Œè¯·ç¡®è®¤ä½ æ¥å—æ­¤éšç§é£é™©
    å¼€å¯? [y/N] > 

[2] é”®ç›˜æ´»è·ƒåº¦æ„ŸçŸ¥ï¼ˆåªç»Ÿè®¡é¢‘ç‡ï¼Œä¸è®°å½•å†…å®¹ï¼‰  é»˜è®¤: å¼€å¯
    å¼€å¯? [Y/n] > 

[3] éº¦å…‹é£è¯­éŸ³è¯†åˆ«  é»˜è®¤: å¼€å¯
    å¼€å¯? [Y/n] > 

ã€TTS è¯­éŸ³åˆæˆæ¨¡å‹ã€‘
L2DClaw ä½¿ç”¨æœ¬åœ° Qwen3 TTS æ¨¡å‹è¿›è¡Œè¯­éŸ³åˆæˆï¼ˆæ— éœ€è”ç½‘ï¼‰ã€‚
æ¨¡å‹å¤§å°çº¦ 1.2GBï¼Œå°†ä¸‹è½½åˆ° ~/.l2dclaw/models/qwen3-tts/

å¼€å§‹ä¸‹è½½ï¼Ÿ[Y/n] > y

æ­£åœ¨ä¸‹è½½ Qwen3 TTS æ¨¡å‹...
[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘] 87% 1.04GB/1.2GB 2.3MB/s

âœ… ä¸‹è½½å®Œæˆï¼
âœ… åˆå§‹åŒ–å®Œæˆï¼ŒL2DClaw å³å°†å¯åŠ¨...
```

**å®ç°è¦æ±‚**ï¼š
- ä½¿ç”¨ `rich` åº“æ¸²æŸ“è¿›åº¦æ¡å’Œæ ·å¼ï¼ˆ`rich.progress`ã€`rich.console`ï¼‰
- ç”¨æˆ·åŒæ„è®¸å¯åæ‰èƒ½ç»§ç»­ï¼ˆå¼ºåˆ¶ `y` ç¡®è®¤ï¼‰
- æˆªå›¾åŠŸèƒ½éœ€é¢å¤–æ˜¾ç¤ºéšç§æç¤ºï¼Œä¸”éœ€è¦äºŒæ¬¡ç¡®è®¤
- é…ç½®ç»“æœå†™å…¥ `~/.l2dclaw/user_prefs.yaml`
- æ ‡å¿—æ–‡ä»¶ `~/.l2dclaw/initialized` å†™å…¥ï¼Œä¹‹åå¯åŠ¨è·³è¿‡å‘å¯¼

### setup/model_downloader.py â€” æœ¬åœ° TTS æ¨¡å‹ä¸‹è½½

**Qwen3 TTS æœ¬åœ°æ¨¡å‹**æ¥è‡ª HuggingFaceï¼š`Qwen/Qwen3-TTS`ï¼ˆæˆ– ModelScope é•œåƒï¼‰

```python
class ModelDownloader:
    MODELS = {
        "qwen3-tts": {
            "hf_repo": "Qwen/Qwen3-TTS",
            "modelscope_repo": "Qwen/Qwen3-TTS",   # å›½å†…é•œåƒ
            "local_path": "~/.l2dclaw/models/qwen3-tts",
            "required_files": ["model.safetensors", "config.json", "tokenizer.json"]
        }
    }
    
    def download(self, model_name: str, use_modelscope: bool = False):
        """
        ä¼˜å…ˆç”¨ huggingface_hub ä¸‹è½½ï¼Œå›½å†…ç½‘ç»œè‡ªåŠ¨åˆ‡æ¢ ModelScopeã€‚
        æ˜¾ç¤º rich è¿›åº¦æ¡ã€‚
        """
        ...
    
    def verify(self, model_name: str) -> bool:
        """éªŒè¯æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§"""
        ...
    
    def is_downloaded(self, model_name: str) -> bool:
        ...
```

**ç½‘ç»œè‡ªé€‚åº”**ï¼šå…ˆå°è¯• HuggingFaceï¼Œè‹¥ 3 ç§’å†…æ— å“åº”åˆ™è‡ªåŠ¨åˆ‡æ¢ ModelScopeï¼ˆå›½å†…ç”¨æˆ·å‹å¥½ï¼‰ã€‚

---

## Step 2ï¼šAdapter æŠ½è±¡åŸºç±»è®¾è®¡

### adapter/base.py â€” AdapterBase

è¿™æ˜¯æ‰€æœ‰ Adapter çš„ç»Ÿä¸€æ¥å£ï¼Œæœªæ¥æ¥å…¥ç¡¬ä»¶è®¾å¤‡æ—¶åªéœ€ç»§æ‰¿æ­¤ç±»ï¼š

```python
from abc import ABC, abstractmethod
from dataclasses import dataclass
from typing import Any, Callable, Optional
import asyncio

@dataclass
class AdapterEvent:
    """Adapter äº§ç”Ÿçš„äº‹ä»¶ï¼Œç»Ÿä¸€æ ¼å¼"""
    adapter_type: str          # "screen" / "voice" / "keyboard" / "hardware_xxx"
    event_type: str            # "window_changed" / "speech" / "typing_burst" / è‡ªå®šä¹‰
    data: dict                 # äº‹ä»¶æ•°æ®è½½è·
    timestamp: str             # ISO æ ¼å¼æ—¶é—´æˆ³
    priority: int = 5          # 1-10ï¼Œä¼˜å…ˆçº§ï¼ˆå½±å“æ˜¯å¦æ‰“æ–­å½“å‰å¯¹è¯ï¼‰

class AdapterBase(ABC):
    """
    æ‰€æœ‰æ„ŸçŸ¥ Adapter çš„æŠ½è±¡åŸºç±»ã€‚
    
    è¦æ¥å…¥æ–°ç¡¬ä»¶/æ•°æ®æºæ—¶ï¼Œç»§æ‰¿æ­¤ç±»å¹¶å®ç°ä»¥ä¸‹æ–¹æ³•å³å¯ï¼š
    
    class MyHardwareAdapter(AdapterBase):
        adapter_type = "hardware_mydevice"
        
        async def initialize(self): ...
        async def start(self): ...
        async def stop(self): ...
        async def get_current_state(self) -> dict: ...
    
    ç„¶ååœ¨ adapter_manager.py ä¸­æ³¨å†Œå³å¯ã€‚
    """
    
    adapter_type: str = "base"           # å­ç±»å¿…é¡»è¦†ç›–
    enabled: bool = True
    
    def __init__(self, config, event_callback: Callable[[AdapterEvent], None]):
        self.config = config
        self.emit = event_callback       # å‘ AdapterManager å‘é€äº‹ä»¶
        self._running = False
    
    @abstractmethod
    async def initialize(self) -> bool:
        """åˆå§‹åŒ–èµ„æºï¼ˆåŠ è½½æ¨¡å‹ã€è¿æ¥è®¾å¤‡ç­‰ï¼‰ï¼Œè¿”å›æ˜¯å¦æˆåŠŸ"""
        ...
    
    @abstractmethod
    async def start(self):
        """å¯åŠ¨åå°é‡‡é›†å¾ªç¯"""
        ...
    
    @abstractmethod
    async def stop(self):
        """åœæ­¢å¹¶é‡Šæ”¾èµ„æº"""
        ...
    
    @abstractmethod
    async def get_current_state(self) -> dict:
        """è·å–å½“å‰å¿«ç…§çŠ¶æ€ï¼ˆä¾› context_builder è°ƒç”¨ï¼‰"""
        ...
    
    def is_available(self) -> bool:
        """æ£€æµ‹å½“å‰å¹³å°/ç¯å¢ƒæ˜¯å¦æ”¯æŒæ­¤ Adapterï¼ˆå­ç±»å¯è¦†ç›–ï¼‰"""
        return True
```

### adapter/adapter_manager.py â€” ç»Ÿä¸€ç®¡ç†

```python
class AdapterManager:
    """
    ç»Ÿä¸€æ³¨å†Œã€å¯åŠ¨ã€åœæ­¢æ‰€æœ‰ Adapterã€‚
    AdapterBase å­ç±»é€šè¿‡ register() æ³¨å…¥ï¼Œæ— éœ€ä¿®æ”¹æ­¤ç±»ã€‚
    """
    
    def register(self, adapter: AdapterBase): ...
    async def start_all(self): ...
    async def stop_all(self): ...
    def get_context_snapshot(self) -> dict:
        """ä»æ‰€æœ‰ Adapter æ”¶é›†å½“å‰çŠ¶æ€ï¼Œåˆå¹¶æˆ context dict"""
        ...
```

### adapter/hardware/hardware_adapter_base.py â€” ç¡¬ä»¶é¢„ç•™æ¥å£

```python
class HardwareAdapterBase(AdapterBase):
    """
    ç¡¬ä»¶è®¾å¤‡ Adapter çš„åŸºç±»ï¼Œåœ¨ AdapterBase åŸºç¡€ä¸Šå¢åŠ ç¡¬ä»¶ç‰¹æœ‰æ¥å£ã€‚
    
    æœªæ¥å¯å®ç°çš„å­ç±»ç¤ºä¾‹ï¼š
    - SerialHardwareAdapter     # ä¸²å£è®¾å¤‡ï¼ˆArduinoã€ä¼ æ„Ÿå™¨ï¼‰
    - HIDHardwareAdapter        # HID è®¾å¤‡ï¼ˆæ‰‹æŸ„ã€ç‰¹æ®Šè¾“å…¥è®¾å¤‡ï¼‰
    - BluetoothHardwareAdapter  # è“ç‰™è®¾å¤‡
    - NetworkHardwareAdapter    # ç½‘ç»œè®¾å¤‡ï¼ˆIoT ä¼ æ„Ÿå™¨ï¼‰
    
    æ¥å…¥æ­¥éª¤ï¼ˆå†™å…¥ docs/adapter_extension_guide.mdï¼‰ï¼š
    1. ç»§æ‰¿ HardwareAdapterBase
    2. å®ç° initialize/start/stop/get_current_state
    3. åœ¨ conf.yaml çš„ adapters.hardware ä¸‹æ·»åŠ é…ç½®
    4. åœ¨ main.py ä¸­ç”¨ adapter_manager.register() æ³¨å†Œå®ä¾‹
    """
    
    adapter_type = "hardware_base"
    
    @abstractmethod
    async def connect(self) -> bool:
        """å»ºç«‹ä¸ç¡¬ä»¶çš„è¿æ¥"""
        ...
    
    @abstractmethod
    async def disconnect(self):
        """æ–­å¼€è¿æ¥"""
        ...
    
    @property
    @abstractmethod
    def device_info(self) -> dict:
        """è¿”å›è®¾å¤‡ä¿¡æ¯ {name, vendor, type, firmware_version}"""
        ...
```

---

## Step 3ï¼šScreenAdapter â€” çª—å£ + ç”»é¢å†…å®¹è¯†åˆ«

### adapter/screen/window_watcher.py â€” è·¨å¹³å°çª—å£ç›‘æ§

**Windows å®ç°**ï¼ˆ`pywin32`ï¼‰ï¼š
```python
import win32gui, win32process, psutil

def get_active_window_win() -> dict:
    hwnd = win32gui.GetForegroundWindow()
    title = win32gui.GetWindowText(hwnd)
    _, pid = win32process.GetWindowThreadProcessId(hwnd)
    process = psutil.Process(pid).name()
    return {"title": title, "process": process}
```

**macOS å®ç°**ï¼ˆ`AppKit` / `subprocess osascript`ï¼‰ï¼š
```python
import subprocess

def get_active_window_mac() -> dict:
    script = '''
    tell application "System Events"
        set frontApp to name of first application process whose frontmost is true
        set frontWindow to ""
        try
            set frontWindow to name of front window of (first application process whose frontmost is true)
        end try
        return frontApp & "|" & frontWindow
    end tell
    '''
    result = subprocess.run(["osascript", "-e", script], capture_output=True, text=True)
    parts = result.stdout.strip().split("|")
    return {"process": parts[0], "title": parts[1] if len(parts) > 1 else ""}
```

**ç»Ÿä¸€å·¥å‚å‡½æ•°**ï¼š
```python
import sys

def get_active_window() -> dict:
    if sys.platform == "win32":
        return get_active_window_win()
    elif sys.platform == "darwin":
        return get_active_window_mac()
    else:
        raise NotImplementedError(f"Platform {sys.platform} not supported")
```

### adapter/screen/content_recognizer.py â€” ç”»é¢å†…å®¹è¯†åˆ«

**ä»…åœ¨ç”¨æˆ·åœ¨å‘å¯¼ä¸­å¼€å¯ `screen_content_recognition: true` æ—¶å¯ç”¨ã€‚**

```python
class ContentRecognizer:
    """
    æˆªå–å±å¹•å†…å®¹ï¼Œè°ƒç”¨ VLMï¼ˆè§†è§‰è¯­è¨€æ¨¡å‹ï¼‰ç†è§£ç”»é¢ã€‚
    æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
    - æ¨¡å¼Aï¼šå‘é€æˆªå›¾ç»™ OpenClawï¼ˆéœ€äº‘ç«¯ VLM æ”¯æŒï¼‰
    - æ¨¡å¼Bï¼šæœ¬åœ° OCR æå–æ–‡å­—ï¼ˆä½¿ç”¨ pytesseract æˆ– easyocrï¼Œæ— éšç§é£é™©ï¼‰
    """
    
    def __init__(self, config):
        self.mode = config.screen_watcher.content_recognition_mode  # "vlm" or "ocr"
        self.capture_region = config.screen_watcher.capture_region  # "fullscreen" or "active_window"
    
    async def capture_and_analyze(self) -> dict:
        screenshot = self._take_screenshot()
        
        if self.mode == "ocr":
            text = self._ocr(screenshot)
            return {"type": "ocr", "content": text[:500]}   # é™åˆ¶é•¿åº¦
        
        elif self.mode == "vlm":
            # å‹ç¼©æˆªå›¾åç¼–ç ä¸º base64ï¼Œé™„åœ¨å‘ç»™ OpenClaw çš„ context ä¸­
            b64 = self._compress_and_encode(screenshot)
            return {"type": "screenshot_b64", "content": b64}
    
    def _take_screenshot(self):
        """è·¨å¹³å°æˆªå›¾ï¼šä½¿ç”¨ Pillow + mss åº“"""
        import mss
        from PIL import Image
        # mss è·¨å¹³å°ï¼ŒWindows/macOS/Linux å‡æ”¯æŒ
        ...
    
    def _compress_and_encode(self, img) -> str:
        """å‹ç¼©åˆ° 720p ä»¥å†…ï¼ŒJPEG å‹ç¼©ï¼Œbase64 ç¼–ç """
        ...
    
    def _ocr(self, img) -> str:
        """ä½¿ç”¨ easyocr æœ¬åœ° OCRï¼Œä¸è”ç½‘"""
        import easyocr
        ...
```

**conf.yaml ä¸­å¯¹åº”é…ç½®**ï¼š
```yaml
screen_watcher:
  enabled: true
  interval_seconds: 5
  capture_window_title: true
  capture_active_process: true
  
  # ç”»é¢å†…å®¹è¯†åˆ«ï¼ˆå‘å¯¼ä¸­é…ç½®ï¼‰
  content_recognition_enabled: false      # å‘å¯¼å†™å…¥
  content_recognition_mode: "ocr"         # "ocr"ï¼ˆæœ¬åœ°æ— éšç§é£é™©ï¼‰æˆ– "vlm"ï¼ˆæˆªå›¾ä¸Šäº‘ï¼‰
  capture_region: "active_window"         # "fullscreen" æˆ– "active_window"
  content_recognition_interval: 15        # å†…å®¹è¯†åˆ«é¢‘ç‡ï¼ˆç§’ï¼‰ï¼Œæ¯”çª—å£é‡‡æ ·æ›´ä½
```

---

## Step 4ï¼šæœ¬åœ° Qwen3 TTS

### tts/base.py â€” TTS æŠ½è±¡åŸºç±»

```python
class TTSBase(ABC):
    @abstractmethod
    async def speak(self, text: str): ...
    
    @abstractmethod
    def stop(self): ...
    
    @abstractmethod
    def is_ready(self) -> bool: ...
```

### tts/local_qwen3_tts.py â€” æœ¬åœ°æ¨ç†

ä½¿ç”¨ä¸‹è½½å¥½çš„ Qwen3 TTS æ¨¡å‹åœ¨æœ¬åœ°è¿›è¡Œè¯­éŸ³åˆæˆï¼š

```python
class LocalQwen3TTS(TTSBase):
    """
    ä½¿ç”¨æœ¬åœ° Qwen3-TTS æ¨¡å‹åˆæˆè¯­éŸ³ï¼Œæ— éœ€è”ç½‘ã€‚
    æ¨¡å‹è·¯å¾„æ¥è‡ª ~/.l2dclaw/models/qwen3-tts/
    
    æ¨ç†åç«¯ä¼˜å…ˆçº§ï¼š
    1. å¦‚æœæœ‰ NVIDIA GPU â†’ ä½¿ç”¨ torch CUDA
    2. å¦‚æœæ˜¯ Apple Silicon â†’ ä½¿ç”¨ torch MPS
    3. å…¶ä»– â†’ CPU æ¨ç†ï¼ˆè¾ƒæ…¢ï¼‰
    """
    
    def __init__(self, config):
        self.model_path = Path.home() / ".l2dclaw" / "models" / "qwen3-tts"
        self.device = self._detect_device()
        self.model = None
        self.processor = None
    
    def _detect_device(self) -> str:
        import torch
        if torch.cuda.is_available():
            return "cuda"
        elif torch.backends.mps.is_available():   # Apple Silicon
            return "mps"
        return "cpu"
    
    async def initialize(self):
        """åŠ è½½æ¨¡å‹åˆ°å†…å­˜ï¼ˆåœ¨ main.py å¯åŠ¨æ—¶è°ƒç”¨ï¼Œéé¦–æ¬¡åˆæˆæ—¶æ‰åŠ è½½ï¼‰"""
        from transformers import AutoProcessor, AutoModel
        self.processor = AutoProcessor.from_pretrained(str(self.model_path))
        self.model = AutoModel.from_pretrained(str(self.model_path)).to(self.device)
    
    async def speak(self, text: str):
        """åˆæˆè¯­éŸ³å¹¶æ’­æ”¾"""
        audio = self._synthesize(text)
        await self._play_audio(audio)
    
    def _synthesize(self, text: str) -> np.ndarray:
        # è°ƒç”¨ Qwen3-TTS æ¨¡å‹æ¨ç†
        ...
    
    async def _play_audio(self, audio: np.ndarray):
        # ä½¿ç”¨ sounddevice æ’­æ”¾ï¼Œæ”¯æŒæå‰åœæ­¢
        import sounddevice as sd
        ...
```

### tts/dashscope_tts.py â€” äº‘ç«¯é™çº§å¤‡ç”¨

å½“æœ¬åœ°æ¨¡å‹åŠ è½½å¤±è´¥æˆ–ç”¨æˆ·é€‰æ‹©äº‘ç«¯æ—¶çš„å¤‡ç”¨æ–¹æ¡ˆï¼Œè°ƒç”¨ DashScope APIã€‚

---

## Step 5ï¼šconf.yaml å®Œæ•´é…ç½®

```yaml
# OpenClaw äº‘ç«¯å¤§è„‘
openclaw:
  base_url: "https://your-openclaw-endpoint/v1"
  api_key: "${OPENCLAW_API_KEY}"
  model: "openclaw-default"
  timeout_seconds: 10
  system_prompt: |
    ä½ æ˜¯ä¸€åªåå« Claw çš„å¯çˆ±æ¡Œå® ã€‚ä½ èƒ½æ„ŸçŸ¥ç”¨æˆ·çš„æ¡Œé¢çŠ¶æ€ã€‚
    è¯·æ ¹æ®ä¸Šä¸‹æ–‡å’Œç”¨æˆ·è¾“å…¥ï¼Œç”¨ç®€çŸ­æ´»æ³¼çš„è¯­æ°”å›åº”ï¼ˆä¸è¶…è¿‡50å­—ï¼‰ã€‚
    ä½ çš„å›å¤å¿…é¡»ä¸¥æ ¼æ˜¯ä»¥ä¸‹ JSON æ ¼å¼ï¼Œä¸åŠ ä»»ä½•å¤šä½™æ–‡å­—ï¼š
    {"text": "è¯´çš„è¯", "emotion": "happy|sad|surprised|neutral|thinking|angry", "motion": "idle|nod|shake|wave|jump"}

# TTS é…ç½®
tts:
  provider: "local_qwen3"         # "local_qwen3"ï¼ˆé»˜è®¤ï¼‰æˆ– "dashscope"ï¼ˆé™çº§å¤‡ç”¨ï¼‰
  voice: "default"
  dashscope_api_key: "${DASHSCOPE_API_KEY}"   # ä»… provider=dashscope æ—¶éœ€è¦

# è¯­éŸ³è¯†åˆ«
asr:
  provider: "faster-whisper"
  model_size: "base"
  language: "zh"
  vad_aggressiveness: 2

# å±å¹•æ„ŸçŸ¥ï¼ˆå…·ä½“é…ç½®ç”±å‘å¯¼å†™å…¥ user_prefs.yamlï¼‰
screen_watcher:
  enabled: true
  interval_seconds: 5
  capture_window_title: true
  capture_active_process: true
  content_recognition_enabled: false       # å‘å¯¼é…ç½®
  content_recognition_mode: "ocr"
  capture_region: "active_window"
  content_recognition_interval: 15

# é”®ç›˜æ´»è·ƒåº¦æ„ŸçŸ¥
keyboard_watcher:
  enabled: true
  track_frequency_only: true               # åªç»Ÿè®¡é¢‘ç‡ï¼Œç»ä¸è®°å½•å†…å®¹

# Adapter æ‰©å±•é…ç½®ï¼ˆç¡¬ä»¶è®¾å¤‡åœ¨æ­¤å¤„æ·»åŠ ï¼‰
adapters:
  hardware: []                             # é¢„ç•™ï¼Œä¾‹å¦‚ï¼š[{type: "serial", port: "COM3"}]

# Live2D
live2d:
  model_path: "live2d_driver/frontend/live2d_models/haru"
  desktop_pet_mode: true
  always_on_top: true
  click_through: true
  window_width: 400
  window_height: 600

# æœåŠ¡ç«¯å£
server:
  driver_ws_port: 12393
  adapter_port: 12394
```

---

## Step 6ï¼šå®ç°å…¶ä½™æ ¸å¿ƒæ¨¡å—

### brain/openclaw_client.py

```python
from openai import AsyncOpenAI
import json

class OpenClawClient:
    def __init__(self, config):
        self.client = AsyncOpenAI(
            base_url=config.openclaw.base_url,
            api_key=config.openclaw.api_key,
            timeout=config.openclaw.timeout_seconds
        )
        self.model = config.openclaw.model
        self.system_prompt = config.openclaw.system_prompt
    
    async def think(self, context: str, user_text: str) -> dict:
        messages = [
            {"role": "system", "content": self.system_prompt},
            {"role": "user", "content": f"[æ¡Œé¢çŠ¶æ€]\n{context}\n\n[ç”¨æˆ·è¯´]\n{user_text}"}
        ]
        response = await self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            response_format={"type": "json_object"}
        )
        return json.loads(response.choices[0].message.content)
```

### adapter/context_builder.py

```python
def build_context(adapter_snapshot: dict) -> str:
    """
    å°† AdapterManager.get_context_snapshot() çš„ç»“æœè½¬æˆè‡ªç„¶è¯­è¨€ context å­—ç¬¦ä¸²ã€‚
    
    è¾“å…¥ç¤ºä¾‹ï¼š
    {
      "screen": {"active_window": "VS Code", "process": "code.exe", "category": "coding",
                 "content": {"type": "ocr", "content": "def main():..."}},
      "keyboard": {"typing_wpm": 45, "active": true},
      "voice": {"last_speech_ago_seconds": 30}
    }
    
    è¾“å‡ºç¤ºä¾‹ï¼š
    "[æ¡Œé¢] ç”¨æˆ·æ­£åœ¨ä½¿ç”¨ VS Code ç¼–å†™ä»£ç 
     [å±å¹•å†…å®¹] ä»£ç ç¼–è¾‘ä¸­ï¼Œæ£€æµ‹åˆ° Python å‡½æ•°å®šä¹‰
     [è¾“å…¥çŠ¶æ€] æ­£åœ¨ç§¯ææ‰“å­—ï¼ˆçº¦45è¯/åˆ†é’Ÿï¼‰
     [æ—¶é—´] ä¸‹åˆ3ç‚¹ï¼Œå‘¨ä¸‰"
    """
    ...
```

### main.py

```python
import asyncio
import sys
from pathlib import Path
from setup.wizard import SetupWizard
from adapter.adapter_manager import AdapterManager
from adapter.screen.screen_adapter import ScreenAdapter
from adapter.voice.voice_adapter import VoiceAdapter
from adapter.keyboard.keyboard_adapter import KeyboardAdapter
from adapter.context_builder import build_context
from brain.openclaw_client import OpenClawClient
from tts.local_qwen3_tts import LocalQwen3TTS
from tts.dashscope_tts import DashscopeTTS
from live2d_driver.driver_server import Live2DDriverServer
from config import load_config

INIT_FLAG = Path.home() / ".l2dclaw" / "initialized"

async def main():
    # Step 1: é¦–æ¬¡å¯åŠ¨æ£€æµ‹
    if not INIT_FLAG.exists():
        wizard = SetupWizard()
        if not wizard.run():      # ç”¨æˆ·æ‹’ç»è®¸å¯æˆ–ä¸­æ–­
            sys.exit(0)
    
    config = load_config("conf.yaml")
    user_prefs = load_user_prefs()   # ~/.l2dclaw/user_prefs.yaml
    
    # Step 2: åˆå§‹åŒ– TTSï¼ˆæœ¬åœ°ä¼˜å…ˆï¼‰
    tts = LocalQwen3TTS(config)
    if not await tts.initialize():
        print("âš  æœ¬åœ° TTS åŠ è½½å¤±è´¥ï¼Œé™çº§ä¸ºäº‘ç«¯ DashScope TTS")
        tts = DashscopeTTS(config)
    
    # Step 3: åˆå§‹åŒ– Adapter
    manager = AdapterManager()
    manager.register(ScreenAdapter(config, user_prefs, manager.on_event))
    manager.register(VoiceAdapter(config, manager.on_event))
    manager.register(KeyboardAdapter(config, manager.on_event))
    # æœªæ¥ç¡¬ä»¶ï¼šmanager.register(MyHardwareAdapter(config, manager.on_event))
    
    # Step 4: åˆå§‹åŒ–å…¶ä»–æ¨¡å—
    driver = Live2DDriverServer(config)
    openclaw = OpenClawClient(config)
    
    # Step 5: äº‹ä»¶å¤„ç†
    async def on_voice_input(text: str):
        context = build_context(manager.get_context_snapshot())
        response = await openclaw.think(context, text)
        await asyncio.gather(
            driver.send_action(response["text"], response["emotion"], response["motion"]),
            tts.speak(response["text"])
        )
    
    manager.set_voice_callback(on_voice_input)
    
    # Step 6: å¯åŠ¨
    await asyncio.gather(
        driver.start(),
        manager.start_all(),
    )

if __name__ == "__main__":
    asyncio.run(main())
```

---

## Step 7ï¼šLive2D å‰ç«¯é›†æˆ

ä» `_upstream_reference` å¤åˆ¶å¹¶è£å‰ªå‰ç«¯åˆ° `live2d_driver/frontend/`ï¼š

1. å¤åˆ¶ Open-LLM-VTuber å‰ç«¯ï¼ˆElectron å®¢æˆ·ç«¯ï¼‰
2. ä¿ç•™ï¼šLive2D æ¸²æŸ“ã€WebSocket é€šä¿¡ã€æ¡Œå® æ¨¡å¼é…ç½®
3. åˆ é™¤ï¼šåŸæœ‰ LLM/TTS/ASR å‰ç«¯ä»£ç ï¼ˆç”±æˆ‘ä»¬ Python åç«¯è´Ÿè´£ï¼‰
4. éªŒè¯ WebSocket åè®®æ ¼å¼ä¸ `driver_server.py` å®Œå…¨åŒ¹é…

---

## requirements.txt

```
# æ ¸å¿ƒ
openai>=1.0.0
websockets>=12.0
pyyaml>=6.0
python-dotenv>=1.0.0

# å‘å¯¼ UI
rich>=13.0.0

# TTS æœ¬åœ°æ¨ç†
torch>=2.0.0
transformers>=4.40.0
sounddevice>=0.4.6
numpy>=1.24.0

# TTS äº‘ç«¯å¤‡ç”¨
dashscope>=1.14.0

# è¯­éŸ³è¯†åˆ«
faster-whisper>=0.10.0
webrtcvad>=2.0.10
pyaudio>=0.2.11

# å±å¹•æ„ŸçŸ¥
psutil>=5.9.0
mss>=9.0.0                          # è·¨å¹³å°æˆªå›¾
Pillow>=10.0.0

# OCRï¼ˆæœ¬åœ°ç”»é¢å†…å®¹è¯†åˆ«ï¼‰
easyocr>=1.7.0

# Windows ä¸“ç”¨ï¼ˆè‡ªåŠ¨æŒ‰å¹³å°å®‰è£…ï¼‰
pywin32>=306; sys_platform == "win32"

# æ¨¡å‹ä¸‹è½½
huggingface_hub>=0.20.0

# é”®ç›˜ç›‘æ§
pynput>=1.7.0                        # è·¨å¹³å°é”®ç›˜ç›‘å¬ï¼ˆåªç»Ÿè®¡é¢‘ç‡ï¼‰
```

---

## å®Œæˆæ ‡å‡† Checklist

**é¦–æ¬¡å¯åŠ¨å‘å¯¼**
- [ ] è®¸å¯åè®®æ˜¾ç¤ºï¼Œå¼ºåˆ¶ç¡®è®¤ `y` æ‰ç»§ç»­
- [ ] æˆªå›¾åŠŸèƒ½æœ‰äºŒæ¬¡éšç§æç¤º
- [ ] Qwen3 TTS æ¨¡å‹è‡ªåŠ¨æ£€æµ‹ HF / ModelScopeï¼Œæ˜¾ç¤ºè¿›åº¦æ¡ä¸‹è½½
- [ ] é…ç½®å†™å…¥ `~/.l2dclaw/user_prefs.yaml`ï¼Œæ ‡å¿—æ–‡ä»¶å†™å…¥

**Adapter å±‚**
- [ ] `AdapterBase` æŠ½è±¡åŸºç±»å®Œæ•´å®šä¹‰
- [ ] `HardwareAdapterBase` é¢„ç•™æ¥å£æ–‡æ¡£é½å…¨
- [ ] `ScreenAdapter` åœ¨ Windows å’Œ macOS å‡èƒ½æ­£ç¡®è¾“å‡ºæ´»è·ƒçª—å£
- [ ] `ContentRecognizer` OCR æ¨¡å¼èƒ½ä»æˆªå›¾æå–æ–‡å­—
- [ ] `VoiceAdapter` èƒ½æ­£ç¡®è§¦å‘è¯­éŸ³è¯†åˆ«å›è°ƒ
- [ ] `AdapterManager` èƒ½ç»Ÿä¸€ç®¡ç†æ‰€æœ‰ Adapter
- [ ] `docs/adapter_extension_guide.md` å†™æ˜å¦‚ä½•æ¥å…¥æ–°ç¡¬ä»¶

**å¤§è„‘ + TTS**
- [ ] `OpenClawClient` æˆåŠŸè°ƒç”¨å¹¶è§£æ JSON å“åº”
- [ ] `LocalQwen3TTS` èƒ½åŠ è½½æœ¬åœ°æ¨¡å‹å¹¶åˆæˆè¯­éŸ³
- [ ] TTS é™çº§é€»è¾‘æ­£å¸¸ï¼ˆæœ¬åœ°å¤±è´¥ â†’ äº‘ç«¯ï¼‰

**æµ‹è¯•è„šæœ¬**
- [ ] `tests/test_screen.py` â€” éªŒè¯çª—å£é‡‡é›†ï¼ˆWin + macOSï¼‰
- [ ] `tests/test_content_ocr.py` â€” éªŒè¯æˆªå›¾ OCR
- [ ] `tests/test_brain.py` â€” éªŒè¯ OpenClaw è°ƒç”¨
- [ ] `tests/test_tts.py` â€” éªŒè¯æœ¬åœ° TTS åˆæˆ
- [ ] `tests/test_adapter_manager.py` â€” éªŒè¯ Adapter æ³¨å†Œå’Œäº‹ä»¶æµ

---

## æ¯é˜¶æ®µ Git æäº¤èŠ‚ç‚¹

```bash
# é˜¶æ®µä¸€ï¼šéª¨æ¶ + å‘å¯¼ + æ ¸å¿ƒæ¨¡å—
git add -A
git commit -m "feat: setup wizard, adapter interface, screen/voice/tts modules"
git push origin main

# é˜¶æ®µäºŒï¼šLive2D å‰ç«¯é›†æˆ
git add -A
git commit -m "feat: integrate Live2D frontend from Open-LLM-VTuber"
git push origin main

# é˜¶æ®µä¸‰ï¼šè”è°ƒ + å†…å®¹è¯†åˆ« + æ–‡æ¡£
git add -A
git commit -m "feat: full pipeline, content recognition, hardware adapter guide"
git push origin main
```

---

## æ³¨æ„äº‹é¡¹

1. **éšç§ä¿æŠ¤**ï¼šæˆªå›¾/VLM æ¨¡å¼éœ€ç”¨æˆ·åœ¨å‘å¯¼ä¸­ä¸»åŠ¨å¼€å¯å¹¶ç¡®è®¤ï¼ŒOCR æ˜¯æ— éšç§é£é™©çš„é»˜è®¤é€‰é¡¹
2. **è·¨å¹³å°**ï¼šæ‰€æœ‰å¹³å°ç›¸å…³ä»£ç å¿…é¡»åŒæ—¶å®ç° Windowsï¼ˆ`sys.platform == "win32"`ï¼‰å’Œ macOSï¼ˆ`sys.platform == "darwin"`ï¼‰åˆ†æ”¯ï¼Œä¸å…è®¸åªå†™ä¸€ä¸ªå¹³å°
3. **Adapter æ‰©å±•æ€§**ï¼š`AdapterBase` çš„æ¥å£è®¾è®¡è¦ç¨³å®šï¼Œä¸èƒ½é¢‘ç¹æ”¹åŠ¨åŸºç±»ï¼ˆé¢å‘æ‰©å±•å¼€æ”¾ï¼Œé¢å‘ä¿®æ”¹å…³é—­ï¼‰
4. **è®¾å¤‡æ£€æµ‹**ï¼šTTS æœ¬åœ°æ¨ç†è‡ªåŠ¨æ£€æµ‹ CUDA / MPSï¼ˆApple Siliconï¼‰/ CPUï¼Œæ— éœ€ç”¨æˆ·æ‰‹åŠ¨é…ç½®
5. **é”™è¯¯å¤„ç†**ï¼šç½‘ç»œè°ƒç”¨ï¼ˆOpenClawã€ä¸‹è½½ï¼‰å¿…é¡»æœ‰è¶…æ—¶å’Œé‡è¯•ï¼›æœ¬åœ°æ¨¡å‹åŠ è½½å¤±è´¥æœ‰é™çº§è·¯å¾„
6. **æ—¥å¿—**ï¼šä½¿ç”¨ `logging` æ¨¡å—ï¼Œä¸ç”¨è£¸ `print`ï¼›å‘å¯¼é˜¶æ®µä½¿ç”¨ `rich.console`

å®Œæˆåè¯·æ±‡æŠ¥ï¼šæ¯ä¸ªæ¨¡å—çš„å®ç°çŠ¶æ€ã€è·¨å¹³å°å…¼å®¹æ€§æƒ…å†µã€é‡åˆ°çš„é—®é¢˜ï¼Œä»¥åŠ Live2D å‰ç«¯é›†æˆçš„ä¸‹ä¸€æ­¥è®¡åˆ’ã€‚
